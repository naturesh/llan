{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE \n",
    "import os\n",
    "import dotenv; dotenv.load_dotenv()\n",
    "from supabase import create_client, Client\n",
    "\n",
    "\n",
    "\n",
    "url = os.environ['PROJECT_URL']\n",
    "key = os.environ['SERVICE_ROLE']\n",
    "\n",
    "supabase: Client = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  langChain GPT-4o-mini task manager.\n",
    "\n",
    "### task manager with nlp\n",
    "\n",
    "\n",
    "#### using library\n",
    "- pgvector ( vectorstore )\n",
    "- supabase database \n",
    "- langgraph \n",
    "- openai embedding, llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY'] = ''\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"llan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from typing import Annotated\n",
    "import datetime\n",
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import pytz, uuid\n",
    "\n",
    "\n",
    "# OpenAI text-embedding-ada-002\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=512)\n",
    "\n",
    "\n",
    "# Supabase vectorstore pgvector \n",
    "vectorstore = SupabaseVectorStore(\n",
    "    client=supabase,\n",
    "    embedding=embeddings,\n",
    "    table_name='tasks',\n",
    "    query_name=\"match_tasks\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPABASE.PY\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def similarity_search_by_vector_with_relevance_scores(\n",
    "        query,\n",
    "        filter,\n",
    "        k = 4,\n",
    "        score_threshold = None,\n",
    "    ):\n",
    "        match_documents_params = vectorstore.match_args(query, filter)\n",
    "        query_builder = vectorstore._client.rpc(vectorstore.query_name, match_documents_params)\n",
    "        query_builder.params = query_builder.params.set(\"limit\", k)\n",
    "\n",
    "        res = query_builder.execute()\n",
    "        match_result = [\n",
    "            (\n",
    "                Document(\n",
    "                    metadata=search.get(\"metadata\", {}),  # type: ignore\n",
    "                    page_content=search.get(\"content\", \"\"),\n",
    "                ),\n",
    "                search.get(\"similarity\", 0.0),\n",
    "                search.get('id', '')\n",
    "            )\n",
    "            for search in res.data\n",
    "            if search.get(\"content\")\n",
    "        ]\n",
    "\n",
    "        if score_threshold is not None:\n",
    "            match_result = [\n",
    "                (doc, id)\n",
    "                for doc, similarity, id in match_result\n",
    "                if similarity >= score_threshold\n",
    "            ]\n",
    "    \n",
    "\n",
    "        return match_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def retriever_tool(query : Annotated[str, 'query'], config: RunnableConfig):\n",
    "    \"Searches for tasks based on a query. Input should be a search query string.\"\n",
    "    configurable = config.get('configurable')\n",
    "\n",
    "    rst = similarity_search_by_vector_with_relevance_scores(\n",
    "        embeddings.embed_query(query),\n",
    "        filter={\"user\": configurable.get('thread_id')},\n",
    "        score_threshold=0.8\n",
    "    )\n",
    "\n",
    "    rstl = []\n",
    "    tz = pytz.timezone(configurable.get('timezone'))\n",
    "\n",
    "    for doc, id in rst:\n",
    "        rstl.append({\n",
    "            'id' : id,\n",
    "            'content' : doc.page_content,\n",
    "            'date'  : datetime.datetime.fromtimestamp(doc.metadata['task_date'], tz).strftime('%Y-%m-%d %H:%M:%S %Z%z'),\n",
    "            'completed' : doc.metadata['completed']\n",
    "        })\n",
    "       \n",
    "        \n",
    "    return rstl\n",
    "\n",
    "\n",
    "\n",
    "# DatetimeParser prompt in langchain\n",
    "# DatetimeParser in langchain \n",
    "DateType = Annotated[str, \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'. Examples: 969-03-01T08:41:26.015244Z, 798-06-03T17:13:25.764744Z, 1519-11-09T23:51:38.563271ZReturn ONLY this string, no other words!\"]\n",
    "def parser(dateString):\n",
    "    return datetime.datetime.strptime(dateString.strip(), \"%Y-%m-%dT%H:%M:%S.%fZ\").timestamp()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add task in vector database with id\n",
    "@tool\n",
    "def addTask(content : Annotated[str, 'something to do'], date : DateType, config: RunnableConfig):\n",
    "    'add tast to database'\n",
    "\n",
    "    try:\n",
    "\n",
    "        configurable = config.get('configurable')\n",
    "        res = vectorstore.add_texts(\n",
    "            texts=[content],\n",
    "            metadatas=[{\n",
    "                'completed' : False,\n",
    "                'task_date' : parser(date),\n",
    "                'user' : configurable.get('thread_id'),\n",
    "            }],\n",
    "        )\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load task with date range (timestamp) \n",
    "@tool\n",
    "def loadTask(startDate : DateType, endDate : DateType, config: RunnableConfig):\n",
    "    'load user task. Returns the task from startDate to endDate.'\n",
    "\n",
    "    try:\n",
    "            \n",
    "        configurable = config.get('configurable')\n",
    "        res = (\n",
    "            supabase.table('tasks').select('content, metadata, id')\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .gte('metadata->>task_date', parser(startDate))\n",
    "            .lte('metadata->>task_date', parser(endDate))\n",
    "            .execute()\n",
    "        )\n",
    "        return res\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def deleteTask(id : Annotated[str,'want delete id of task'], config: RunnableConfig):\n",
    "    'delete user task with id. Use it carefully only when the user wants to delete it'\n",
    "\n",
    "    try:\n",
    "            \n",
    "        configurable = config.get('configurable')\n",
    "        res = (\n",
    "            supabase.table('tasks')\n",
    "            .delete()\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .eq('id', id)\n",
    "            .execute()\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "\n",
    "@tool\n",
    "def changeCompletedOfTask(id : Annotated[str,'id of the task (that you want to change the \"completed\")'], config: RunnableConfig):\n",
    "    'change \"completed\" of task with task id'\n",
    "\n",
    "    try:\n",
    "            \n",
    "        configurable = config.get('configurable')\n",
    "        res = (\n",
    "            supabase.table('tasks')\n",
    "            .select('metadata')\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .eq('id', id)\n",
    "            .execute()\n",
    "        )\n",
    "        \n",
    "        metadata = res.data[0]['metadata']\n",
    "        metadata['completed'] = True\n",
    "\n",
    "        res = (\n",
    "            supabase.table('tasks')\n",
    "            .update({'metadata': metadata})\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .eq('id', id)\n",
    "            .execute()\n",
    "        )\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "\n",
    "\n",
    "tools = [addTask, loadTask, retriever_tool, deleteTask, changeCompletedOfTask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        result = self.runnable.invoke({\n",
    "            **state,\n",
    "            'time': config.get('configurable').get('time'),\n",
    "            'timezone': config.get('configurable').get('timezone')\n",
    "        })\n",
    "        return {'messages': result}\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"You are a competent secretary; meticulously add and manage users' schedules to the database.\"\n",
    "            \"If an error occurs, please stop and report it immediately.\"\n",
    "            'current time : {time}'\n",
    "            'timezone : {timezone}'\n",
    "        ),\n",
    "        ('placeholder', '{messages}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12b887e60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('assistant', Assistant(assistant_runnable))\n",
    "builder.add_node('tools', ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, 'assistant')\n",
    "builder.add_conditional_edges(\n",
    "    'assistant',\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge('tools', 'assistant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import Connection\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "\n",
    "connection_kwargs = {\n",
    "    \"autocommit\": True,\n",
    "    \"prepare_threshold\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "conn =  Connection.connect(os.environ['PROJECT_DATABASE_URL'], **connection_kwargs)\n",
    "checkpointer = PostgresSaver(conn)\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    request = [\n",
    "\n",
    "        {\n",
    "            \"messages\": (\"user\", '지금 몇시지')\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"configurable\": \n",
    "                {\n",
    "                    \"thread_id\": '38a970b2-8f2a-406d-b52c-34dc490773f0',\n",
    "                    'time' : '2024-10-09-21:30',\n",
    "                    'timezone' : 'Asia/Seoul'\n",
    "                }\n",
    "        },\n",
    "\n",
    "    ]\n",
    "\n",
    "    # for event in graph.stream(\n",
    "    #     *request,stream_mode=\"values\",\n",
    "    # ):\n",
    "    #     event[\"messages\"][-1].pretty_print()\n",
    "    import pprint\n",
    "\n",
    "    pprint.pprint(graph.invoke(*request,stream_mode=\"values\"))\n",
    "\n",
    "\n",
    "    # request[0]['messages'][1] = '안녕 친구?'\n",
    "\n",
    "\n",
    "\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
