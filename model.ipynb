{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE \n",
    "import os\n",
    "import dotenv; dotenv.load_dotenv()\n",
    "from supabase import create_client, Client\n",
    "\n",
    "\n",
    "\n",
    "url = os.environ['PROJECT_URL']\n",
    "key = os.environ['SERVICE_ROLE']\n",
    "\n",
    "supabase: Client = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  langChain GPT-4o-mini task manager.\n",
    "\n",
    "### task manager with nlp\n",
    "\n",
    "\n",
    "#### using library\n",
    "- pgvector ( vectorstore )\n",
    "- supabase database \n",
    "- langgraph \n",
    "- openai embedding, llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY'] = ''\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"llan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from typing import Annotated\n",
    "import datetime\n",
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import pytz, uuid\n",
    "\n",
    "\n",
    "# OpenAI text-embedding-ada-002\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=512)\n",
    "\n",
    "\n",
    "# Supabase vectorstore pgvector \n",
    "vectorstore = SupabaseVectorStore(\n",
    "    client=supabase,\n",
    "    embedding=embeddings,\n",
    "    table_name='tasks',\n",
    "    query_name=\"match_tasks\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPABASE.PY\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def similarity_search_by_vector_with_relevance_scores(\n",
    "        query,\n",
    "        filter,\n",
    "        k = 4,\n",
    "        score_threshold = None,\n",
    "    ):\n",
    "        match_documents_params = vectorstore.match_args(query, filter)\n",
    "        query_builder = vectorstore._client.rpc(vectorstore.query_name, match_documents_params)\n",
    "        query_builder.params = query_builder.params.set(\"limit\", k)\n",
    "\n",
    "        res = query_builder.execute()\n",
    "        match_result = [\n",
    "            (\n",
    "                Document(\n",
    "                    metadata=search.get(\"metadata\", {}),  # type: ignore\n",
    "                    page_content=search.get(\"content\", \"\"),\n",
    "                ),\n",
    "                search.get(\"similarity\", 0.0),\n",
    "                search.get('id', '')\n",
    "            )\n",
    "            for search in res.data\n",
    "            if search.get(\"content\")\n",
    "        ]\n",
    "\n",
    "        if score_threshold is not None:\n",
    "            match_result = [\n",
    "                (doc, id)\n",
    "                for doc, similarity, id in match_result\n",
    "                if similarity >= score_threshold\n",
    "            ]\n",
    "    \n",
    "\n",
    "        return match_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def retriever_tool(query : Annotated[str, 'query'], config: RunnableConfig):\n",
    "    \"Searches for tasks based on a query. Input should be a search query string.\"\n",
    "    configurable = config.get('configurable')\n",
    "\n",
    "    rst = similarity_search_by_vector_with_relevance_scores(\n",
    "        embeddings.embed_query(query),\n",
    "        filter={\"user\": configurable.get('thread_id')},\n",
    "        score_threshold=0.8\n",
    "    )\n",
    "\n",
    "    rstl = []\n",
    "    tz = pytz.timezone(configurable.get('timezone'))\n",
    "\n",
    "    for doc, id in rst:\n",
    "        rstl.append({\n",
    "            'id' : id,\n",
    "            'content' : doc.page_content,\n",
    "            'date'  : datetime.datetime.fromtimestamp(doc.metadata['task_date'], tz).strftime('%Y-%m-%d %H:%M:%S %Z%z'),\n",
    "            'completed' : doc.metadata['completed']\n",
    "        })\n",
    "       \n",
    "        \n",
    "    return rstl\n",
    "\n",
    "\n",
    "\n",
    "# DatetimeParser prompt in langchain\n",
    "# DatetimeParser in langchain \n",
    "DateType = Annotated[str, \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'. Examples: 969-03-01T08:41:26.015244Z, 798-06-03T17:13:25.764744Z, 1519-11-09T23:51:38.563271ZReturn ONLY this string, no other words!\"]\n",
    "def parser(dateString):\n",
    "    return datetime.datetime.strptime(dateString.strip(), \"%Y-%m-%dT%H:%M:%S.%fZ\").timestamp()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add task in vector database with id\n",
    "@tool\n",
    "def addTask(content : Annotated[str, 'something to do'], date : DateType, config: RunnableConfig):\n",
    "    'add tast to database'\n",
    "\n",
    "    try:\n",
    "\n",
    "        configurable = config.get('configurable')\n",
    "        res = vectorstore.add_texts(\n",
    "            texts=[content],\n",
    "            metadatas=[{\n",
    "                'completed' : False,\n",
    "                'task_date' : parser(date),\n",
    "                'user' : configurable.get('thread_id'),\n",
    "            }],\n",
    "        )\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load task with date range (timestamp) \n",
    "@tool\n",
    "def loadTask(startDate : DateType, endDate : DateType, config: RunnableConfig):\n",
    "    'load user task. Returns the task from startDate to endDate.'\n",
    "\n",
    "    try:\n",
    "            \n",
    "        configurable = config.get('configurable')\n",
    "        res = (\n",
    "            supabase.table('tasks').select('content, metadata, id')\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .gte('metadata->>task_date', parser(startDate))\n",
    "            .lte('metadata->>task_date', parser(endDate))\n",
    "            .execute()\n",
    "        )\n",
    "        return res\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def deleteTask(id : Annotated[str,'want delete id of task'], config: RunnableConfig):\n",
    "    'delete user task with id. Use it carefully only when the user wants to delete it'\n",
    "\n",
    "    try:\n",
    "            \n",
    "        configurable = config.get('configurable')\n",
    "        res = (\n",
    "            supabase.table('tasks')\n",
    "            .delete()\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .eq('id', id)\n",
    "            .execute()\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "\n",
    "@tool\n",
    "def changeCompletedOfTask(id : Annotated[str,'id of the task (that you want to change the \"completed\")'], config: RunnableConfig):\n",
    "    'change \"completed\" of task with task id'\n",
    "\n",
    "    try:\n",
    "            \n",
    "        configurable = config.get('configurable')\n",
    "        res = (\n",
    "            supabase.table('tasks')\n",
    "            .select('metadata')\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .eq('id', id)\n",
    "            .execute()\n",
    "        )\n",
    "        \n",
    "        metadata = res.data[0]['metadata']\n",
    "        metadata['completed'] = True\n",
    "\n",
    "        res = (\n",
    "            supabase.table('tasks')\n",
    "            .update({'metadata': metadata})\n",
    "            .eq('metadata->>user', configurable.get('thread_id'))\n",
    "            .eq('id', id)\n",
    "            .execute()\n",
    "        )\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "\n",
    "\n",
    "tools = [addTask, loadTask, retriever_tool, deleteTask, changeCompletedOfTask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        result = self.runnable.invoke({\n",
    "            **state,\n",
    "            'time': config.get('configurable').get('time'),\n",
    "            'timezone': config.get('configurable').get('timezone')\n",
    "        })\n",
    "        return {'messages': result}\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"You are a competent secretary; meticulously add and manage users' schedules to the database.\"\n",
    "            \"If an error occurs, please stop and report it immediately.\"\n",
    "            'current time : {time}'\n",
    "            'timezone : {timezone}'\n",
    "        ),\n",
    "        ('placeholder', '{messages}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12b887e60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('assistant', Assistant(assistant_runnable))\n",
    "builder.add_node('tools', ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, 'assistant')\n",
    "builder.add_conditional_edges(\n",
    "    'assistant',\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge('tools', 'assistant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import Connection\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "\n",
    "connection_kwargs = {\n",
    "    \"autocommit\": True,\n",
    "    \"prepare_threshold\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "conn =  Connection.connect(os.environ['PROJECT_DATABASE_URL'], **connection_kwargs)\n",
    "checkpointer = PostgresSaver(conn)\n",
    "\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicatePreparedStatement",
     "evalue": "prepared statement \"_pg3_0\" already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicatePreparedStatement\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# for event in graph.stream(\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     *request,stream_mode=\"values\",\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     event[\"messages\"][-1].pretty_print()\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m pprint\u001b[38;5;241m.\u001b[39mpprint(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# request[0]['messages'][1] = '안녕 친구?'\u001b[39;00m\n\u001b[1;32m     38\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1560\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1559\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1560\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1248\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_modes:\n\u001b[1;32m   1245\u001b[0m     config[CONF][CONFIG_KEY_STREAM_WRITER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m c: stream\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m   1246\u001b[0m         ((), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m, c)\n\u001b[1;32m   1247\u001b[0m     )\n\u001b[0;32m-> 1248\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SyncPregelLoop(\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1250\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput, stream_modes),\n\u001b[1;32m   1251\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   1252\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[1;32m   1253\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[1;32m   1254\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[1;32m   1255\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m   1256\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   1257\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[1;32m   1258\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   1259\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[1;32m   1262\u001b[0m         submit\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m   1263\u001b[0m         put_writes\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39mput_writes,\n\u001b[1;32m   1264\u001b[0m     )\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/pregel/loop.py:727\u001b[0m, in \u001b[0;36mSyncPregelLoop.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CheckpointNotLatest\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer:\n\u001b[0;32m--> 727\u001b[0m     saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langgraph/checkpoint/postgres/__init__.py:228\u001b[0m, in \u001b[0;36mPostgresSaver.get_tuple\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    225\u001b[0m     where \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWHERE thread_id = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m AND checkpoint_ns = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ORDER BY checkpoint_id DESC LIMIT 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[0;32m--> 228\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSELECT_SQL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m cur:\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointTuple(\n\u001b[1;32m    236\u001b[0m             {\n\u001b[1;32m    237\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_writes(value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpending_writes\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m    261\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/psycopg/cursor.py:97\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, params, prepare, binary)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_gen(query, params, prepare\u001b[38;5;241m=\u001b[39mprepare, binary\u001b[38;5;241m=\u001b[39mbinary)\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m e\u001b[38;5;241m.\u001b[39m_NO_TRACEBACK \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mDuplicatePreparedStatement\u001b[0m: prepared statement \"_pg3_0\" already exists"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    request = [\n",
    "\n",
    "        {\n",
    "            \"messages\": (\"user\", '지금 몇시지')\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"configurable\": \n",
    "                {\n",
    "                    \"thread_id\": '38a970b2-8f2a-406d-b52c-34dc490773f0',\n",
    "                    'time' : '2024-10-09-21:30',\n",
    "                    'timezone' : 'Asia/Seoul'\n",
    "                }\n",
    "        },\n",
    "\n",
    "    ]\n",
    "\n",
    "    # for event in graph.stream(\n",
    "    #     *request,stream_mode=\"values\",\n",
    "    # ):\n",
    "    #     event[\"messages\"][-1].pretty_print()\n",
    "    import pprint\n",
    "\n",
    "    pprint.pprint(graph.invoke(*request,stream_mode=\"values\"))\n",
    "\n",
    "\n",
    "    # request[0]['messages'][1] = '안녕 친구?'\n",
    "\n",
    "\n",
    "\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
